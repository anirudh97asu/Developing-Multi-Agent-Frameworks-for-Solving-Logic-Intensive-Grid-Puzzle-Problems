{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.llm_engine.gemini_agent import Agent\n",
    "\n",
    "#agent = ChatAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Mistral-7b</th>\n",
       "      <th>Llama-13b</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>Claude-3</th>\n",
       "      <th>actual_question</th>\n",
       "      <th>Clues</th>\n",
       "      <th>categories</th>\n",
       "      <th>number_of_clues</th>\n",
       "      <th>number_categories</th>\n",
       "      <th>category_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341.json</td>\n",
       "      <td>802</td>\n",
       "      <td>Nicholas and Edith are having a small dinner p...</td>\n",
       "      <td>1984 | Annata Branco | gewurztraminer\\n1988 | ...</td>\n",
       "      <td>| 1984 | Annata Branco | gewurztraminer |\\n |-...</td>\n",
       "      <td>Let's solve the puzzle step by step.\\n \\n Step...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 6, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>Nicholas and Edith are having a small dinner p...</td>\n",
       "      <td>Clues:\\n1. The Ece Suss was bottled sometime a...</td>\n",
       "      <td>vintages : 1984, 1988, 1992, 1996.\\nwines : An...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>vintages wines types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341.json</td>\n",
       "      <td>726</td>\n",
       "      <td>The world-famous Punta Santiago Rose Gardening...</td>\n",
       "      <td>first | bon silene | Renee\\nsecond | perle d'o...</td>\n",
       "      <td>| first | calocarpa | Hannah\\n |---------|----...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>The world-famous Punta Santiago Rose Gardening...</td>\n",
       "      <td>Clues:\\n1. The rose that won fourth place was ...</td>\n",
       "      <td>placements : first, second, third, fourth.\\nro...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>placements roses gardeners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341.json</td>\n",
       "      <td>16</td>\n",
       "      <td>A standardized test has recently been develope...</td>\n",
       "      <td>55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...</td>\n",
       "      <td>| 55% | Zeno | CIT |\\n |------|------|-----|\\n...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 2, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, Pr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, we...</td>\n",
       "      <td>A standardized test has recently been develope...</td>\n",
       "      <td>Clues:\\n1. Zeno finished with a score that was...</td>\n",
       "      <td>scores : 55%, 62%, 69%, 76%.\\na.i. : Archimede...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>scores institutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341.json</td>\n",
       "      <td>698</td>\n",
       "      <td>Gil Glabbers has lived on the coast of Guernse...</td>\n",
       "      <td>1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...</td>\n",
       "      <td>| 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 2, Tr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Gil Glabbers has lived on the coast of Guernse...</td>\n",
       "      <td>Clues:\\n1. The message from Plymouth was sent ...</td>\n",
       "      <td>year sent : 1962, 1969, 1976, 1983.\\nwriters :...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>sent writers origins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341.json</td>\n",
       "      <td>444</td>\n",
       "      <td>Jamie never misses an opportunity to watch the...</td>\n",
       "      <td>2 | April 22 | Eastbrook\\n9 | April 10 | Islet...</td>\n",
       "      <td>| Dates | Locations |\\n |---|---|\\n | April 10...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n Step 1: Analyze th...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Jamie never misses an opportunity to watch the...</td>\n",
       "      <td>Clues:\\n1. The outing to Eastbrook logged 7 fe...</td>\n",
       "      <td>shooting stars : 2, 9, 16, 23.\\ndates : April ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>stars dates locations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key   id                                           question  \\\n",
       "0  341.json  802  Nicholas and Edith are having a small dinner p...   \n",
       "1  341.json  726  The world-famous Punta Santiago Rose Gardening...   \n",
       "2  341.json   16  A standardized test has recently been develope...   \n",
       "3  341.json  698  Gil Glabbers has lived on the coast of Guernse...   \n",
       "4  341.json  444  Jamie never misses an opportunity to watch the...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  1984 | Annata Branco | gewurztraminer\\n1988 | ...   \n",
       "1  first | bon silene | Renee\\nsecond | perle d'o...   \n",
       "2  55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...   \n",
       "3  1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...   \n",
       "4  2 | April 22 | Eastbrook\\n9 | April 10 | Islet...   \n",
       "\n",
       "                                          Mistral-7b  \\\n",
       "0  | 1984 | Annata Branco | gewurztraminer |\\n |-...   \n",
       "1  | first | calocarpa | Hannah\\n |---------|----...   \n",
       "2  | 55% | Zeno | CIT |\\n |------|------|-----|\\n...   \n",
       "3  | 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...   \n",
       "4  | Dates | Locations |\\n |---|---|\\n | April 10...   \n",
       "\n",
       "                                           Llama-13b  \\\n",
       "0  Let's solve the puzzle step by step.\\n \\n Step...   \n",
       "1  Let's break down the clues step by step:\\n \\n ...   \n",
       "2  Let's break down the clues and solve the puzzl...   \n",
       "3  Let's break down the clues step by step:\\n \\n ...   \n",
       "4  Let's break down the clues and solve the puzzl...   \n",
       "\n",
       "                                          gemini-pro  \\\n",
       "0  Step-by-step solution:\\n 1. From clue 6, we kn...   \n",
       "1  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "2  Step-by-step solution:\\n 1. From clue 2, we kn...   \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "\n",
       "                                         gpt-4-turbo  \\\n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...   \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, Pr...   \n",
       "3  Step-by-step solution:\\n \\n 1. From Clue 2, Tr...   \n",
       "4  Step-by-step solution:\\n \\n Step 1: Analyze th...   \n",
       "\n",
       "                                            Claude-3  \\\n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...   \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, we...   \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "\n",
       "                                     actual_question  \\\n",
       "0  Nicholas and Edith are having a small dinner p...   \n",
       "1  The world-famous Punta Santiago Rose Gardening...   \n",
       "2  A standardized test has recently been develope...   \n",
       "3  Gil Glabbers has lived on the coast of Guernse...   \n",
       "4  Jamie never misses an opportunity to watch the...   \n",
       "\n",
       "                                               Clues  \\\n",
       "0  Clues:\\n1. The Ece Suss was bottled sometime a...   \n",
       "1  Clues:\\n1. The rose that won fourth place was ...   \n",
       "2  Clues:\\n1. Zeno finished with a score that was...   \n",
       "3  Clues:\\n1. The message from Plymouth was sent ...   \n",
       "4  Clues:\\n1. The outing to Eastbrook logged 7 fe...   \n",
       "\n",
       "                                          categories  number_of_clues  \\\n",
       "0  vintages : 1984, 1988, 1992, 1996.\\nwines : An...                6   \n",
       "1  placements : first, second, third, fourth.\\nro...                5   \n",
       "2  scores : 55%, 62%, 69%, 76%.\\na.i. : Archimede...                5   \n",
       "3  year sent : 1962, 1969, 1976, 1983.\\nwriters :...                5   \n",
       "4  shooting stars : 2, 9, 16, 23.\\ndates : April ...                4   \n",
       "\n",
       "   number_categories              category_names  \n",
       "0                  3        vintages wines types  \n",
       "1                  3  placements roses gardeners  \n",
       "2                  2         scores institutions  \n",
       "3                  3        sent writers origins  \n",
       "4                  3       stars dates locations  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"../data/GridPuzzle_processed.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.__init__() missing 1 required positional argument: 'agent_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# system_prompt = \"\"\"You are a helpful AI assistant for logic grid puzzles. When given clues and categories:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Break down each clue into detailed logical steps.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Your goal is to help people understand how to solve the puzzle through logical deduction. Show your thought-process only\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# without the final answer\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a logic grid puzzle solving assistant that produces clear deductive steps. When solving puzzles:\u001b[39m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m1. Skip repeating the original clues - assume they\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre already understood.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124mYour output should read like the step-by-step solution path in a puzzle solver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms notebook, and do not return any solution directly.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Agent.__init__() missing 1 required positional argument: 'agent_name'"
     ]
    }
   ],
   "source": [
    "# system_prompt = \"\"\"You are a helpful AI assistant for logic grid puzzles. When given clues and categories:\n",
    "\n",
    "# Break down each clue into detailed logical steps.\n",
    "# Look for hidden connections between different clues.\n",
    "# Explain your reasoning clearly, one step at a time.\n",
    "# If a clue seems unclear, check your previous steps for helpful information.\n",
    "# Converge after you have processed all the clues\n",
    "\n",
    "# Your goal is to help people understand how to solve the puzzle through logical deduction. Show your thought-process only\n",
    "# without the final answer\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"You are a logic grid puzzle solving assistant that produces clear deductive steps. When solving puzzles:\n",
    "\n",
    "1. Skip repeating the original clues - assume they're already understood.\n",
    "\n",
    "2. Start immediately with meaningful deductions derived from combining and analyzing clues.\n",
    "\n",
    "3. For each numbered deduction step:\n",
    "   - Present only the NEW inference or conclusion reached\n",
    "   - Briefly explain which constraints led to this conclusion\n",
    "   - Show any concrete mappings or assignments that result (X = Y, A cannot be B, etc.)\n",
    "\n",
    "4. Include specific variable assignments and eliminations in your steps (e.g., \"Wine A must be from 1988\" or \"Person B cannot have the red car\").\n",
    "\n",
    "5. Focus on recording the mapping progression - which variables have been definitively assigned and which possibilities have been eliminated.\n",
    "\n",
    "6. Document crucial decision points and branching logic when necessary.\n",
    "\n",
    "7. Each step must contribute new information toward the solution without repeating previous deductions.\n",
    "\n",
    "8. When appropriate, summarize the current state of the solution grid after significant deductions.\n",
    "\n",
    "Your output should read like the step-by-step solution path in a puzzle solver's notebook, and do not return any solution directly.\"\"\"\n",
    "agent = Agent(system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clues = df[\"Clues\"].iloc[0]\n",
    "categories = df[\"categories\"].iloc[0]\n",
    "\n",
    "user_query = clues + \"\\n\" + categories\n",
    "\n",
    "llm_agent_response = agent.perform_action(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's solve this logic puzzle step-by-step.\n",
      "\n",
      "1.  From clues 1 and 5, we know the bottling order is Annata Branco -> Ece Suss -> Bianca Flaux.\n",
      "\n",
      "2.  Clue 2 tells us Bianca Flaux was bottled 4 years before the Vendemmia. This means they cannot be 1984 and 1988 respectively, or 1992 and 1996 respectively.\n",
      "\n",
      "3.  Clue 6 states the 1984 bottle is a gewurztraminer.\n",
      "\n",
      "    *   1984 = gewurztraminer\n",
      "\n",
      "4.  Clue 3 states the 1988 bottle is a pinot noir.\n",
      "\n",
      "    *   1988 = pinot noir\n",
      "\n",
      "5.  Combining deductions 1 and 2, we can infer that Annata Branco cannot be the Vendemmia, and Bianca Flaux cannot be the Annata Branco.\n",
      "\n",
      "6.  From clue 4, the merlot is either the Annata Branco or the Bianca Flaux.\n",
      "\n",
      "7.  Since the Bianca Flaux was bottled before the Vendemmia (clue 2), and the Annata Branco was bottled before the Ece Suss and Bianca Flaux (clue 1 and 5), the Annata Branco cannot be the 1996 vintage.\n",
      "\n",
      "8.  The Bianca Flaux cannot be 1984 (gewurztraminer) or 1988 (pinot noir).\n",
      "\n",
      "9.  The Vendemmia cannot be 1984 (gewurztraminer) or 1988 (pinot noir).\n",
      "\n",
      "10. Since the Bianca Flaux was bottled 4 years before the Vendemmia (clue 2), and the only remaining possibilities are 1992 and 1996, we can deduce that Bianca Flaux = 1992 and Vendemmia = 1996.\n",
      "\n",
      "    *   Bianca Flaux = 1992\n",
      "    *   Vendemmia = 1996\n",
      "\n",
      "11. Since the Bianca Flaux is 1992, and the bottling order is Annata Branco -> Ece Suss -> Bianca Flaux, the Annata Branco must be 1984 and the Ece Suss must be 1988.\n",
      "\n",
      "    *   Annata Branco = 1984\n",
      "    *   Ece Suss = 1988\n",
      "\n",
      "12. Now we can fill in the types. Annata Branco = 1984 = gewurztraminer, Ece Suss = 1988 = pinot noir, Bianca Flaux = 1992, and Vendemmia = 1996.\n",
      "\n",
      "13. Since the merlot is either the Annata Branco or the Bianca Flaux (clue 4), and the Annata Branco is the gewurztraminer, the Bianca Flaux must be the merlot.\n",
      "\n",
      "    *   Bianca Flaux = merlot\n",
      "\n",
      "14. The only remaining type is riesling, so the Vendemmia must be the riesling.\n",
      "\n",
      "    *   Vendemmia = riesling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(llm_agent_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def initialize_probability_tables(num_categories, categories, cat_topics):\n",
    "    \"\"\"\n",
    "    Initialize uniform probability matrices for all pairs of categories.\n",
    "    \n",
    "    Parameters:\n",
    "    num_categories: int - Number of categories\n",
    "    categories: list - List of category strings with comma-separated subcategories\n",
    "    \n",
    "    Returns:\n",
    "    matrices: dict - Maps category index tuples to probability matrices\n",
    "    category_mapping: dict - Maps topic strings to category index tuples\n",
    "    \n",
    "    Example:\n",
    "    >>> matrices, mapping = initialize_probability_tables(3, [\"red, blue\", \"small, large\", \"cheap, expensive\"])\n",
    "    \"\"\"\n",
    "    r = 2\n",
    "    combinations_ls = list(combinations(np.arange(num_categories), r))\n",
    "    matrices = {}\n",
    "    for index, combination in enumerate(combinations_ls):\n",
    "        c1 , c2 = categories[combination[0]].split(\", \"), categories[combination[1]].split(\", \")\n",
    "       \n",
    "        matrix =  np.full((len(c1), len(c2)), 1 / max(len(c1), len(c2)))\n",
    "        topic = cat_topics[combination[0]] + \"x\" + cat_topics[combination[1]]\n",
    "        matrices[topic] = matrix\n",
    "       \n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['vintages', 'wines', 'types']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "cat_topics = []\n",
    "categories = []\n",
    "cat_str = df[\"categories\"].iloc[0].split(\"\\n\")\n",
    "for item in cat_str:\n",
    "    cat_topics.append(item.split(\" : \")[0])\n",
    "    categories.append(item.split(\" : \")[1])\n",
    "\n",
    "print(type(cat_topics), cat_topics)\n",
    "\n",
    "probability_matrices = initialize_probability_tables(len(categories), categories, cat_topics) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def populate_categories(categories):\n",
    "    \n",
    "    cat_topics = []\n",
    "    categories = []\n",
    "\n",
    "    cat_str = df[\"categories\"].iloc[0].split(\"\\n\")\n",
    "    for item in cat_str:\n",
    "        cat_topics.append(item.split(\" : \")[0])\n",
    "        categories.append(item.split(\" : \")[1].split(\", \"))\n",
    "\n",
    "    examples = []\n",
    "    r = 2\n",
    "    combinations_ls = list(combinations(np.arange(len(cat_topics)), r))\n",
    "\n",
    "    for topic_cob in combinations_ls:\n",
    "        key_1, key_2 = topic_cob\n",
    "        for i in range(len(categories[0])):\n",
    "            for j in range(len(categories[0])):\n",
    "\n",
    "                examples.append((categories[key_1][i], categories[key_2][j]))\n",
    "\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_job = f\"\"\"You are given a set of logical deductions to solve a problem and a bunch of probability matries that you can use to modify\n",
    "                        and give weightage to the cateogires based on the logical deduction.\n",
    "                        Here are the items you have access to:\n",
    "                        'Logical Step-By-Step Deductions': {llm_agent_response},\n",
    "                        'Initial Probability Matrices': {probability_matrices}\n",
    "                    \n",
    "                        \"\"\"\n",
    "\n",
    "system_prompt = \"\"\"Analyze each logical deduction step and convert it to matrix probability updates in this format:\n",
    "               (\"matrix_name\", probability_value, row_index, column_index)\n",
    "\n",
    "               Use these probability values:\n",
    "               - Definite: 1.0\n",
    "               - Eliminated: 0.0\n",
    "               - Uncertain: 0.5\n",
    "               - Most Likely: 0.6-0.9\n",
    "              \n",
    "               Remember you have to send a series of probability values that you want to update.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down the logical deductions and update the probability matrices accordingly.\n",
      "\n",
      "**Deduction 1: From clues 1 and 5, we know the bottling order is Annata Branco -> Ece Suss -> Bianca Flaux.**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided. It establishes an order, but the matrices deal with pairings.\n",
      "\n",
      "**Deduction 2: Clue 2 tells us Bianca Flaux was bottled 4 years before the Vendemmia. This means they cannot be 1984 and 1988 respectively, or 1992 and 1996 respectively.**\n",
      "\n",
      "*   This deduction is already incorporated in deduction 10.\n",
      "\n",
      "**Deduction 3: Clue 6 states the 1984 bottle is a gewurztraminer.**\n",
      "\n",
      "*   1984 = gewurztraminer\n",
      "\n",
      "```\n",
      "(\"vintagesxtypes\", 1.0, 0, 0) # 1984 is gewurztraminer\n",
      "(\"vintagesxtypes\", 0.0, 0, 1) # 1984 is not merlot\n",
      "(\"vintagesxtypes\", 0.0, 0, 2) # 1984 is not pinot noir\n",
      "(\"vintagesxtypes\", 0.0, 0, 3) # 1984 is not riesling\n",
      "```\n",
      "\n",
      "**Deduction 4: Clue 3 states the 1988 bottle is a pinot noir.**\n",
      "\n",
      "*   1988 = pinot noir\n",
      "\n",
      "```\n",
      "(\"vintagesxtypes\", 1.0, 1, 2) # 1988 is pinot noir\n",
      "(\"vintagesxtypes\", 0.0, 1, 0) # 1988 is not gewurztraminer\n",
      "(\"vintagesxtypes\", 0.0, 1, 1) # 1988 is not merlot\n",
      "(\"vintagesxtypes\", 0.0, 1, 3) # 1988 is not riesling\n",
      "```\n",
      "\n",
      "**Deduction 5: Combining deductions 1 and 2, we can infer that Annata Branco cannot be the Vendemmia, and Bianca Flaux cannot be the Annata Branco.**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided.\n",
      "\n",
      "**Deduction 6: From clue 4, the merlot is either the Annata Branco or the Bianca Flaux.**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided.\n",
      "\n",
      "**Deduction 7: Since the Bianca Flaux was bottled before the Vendemmia (clue 2), and the Annata Branco was bottled before the Ece Suss and Bianca Flaux (clue 1 and 5), the Annata Branco cannot be the 1996 vintage.**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided.\n",
      "\n",
      "**Deduction 8: The Bianca Flaux cannot be 1984 (gewurztraminer) or 1988 (pinot noir).**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided.\n",
      "\n",
      "**Deduction 9: The Vendemmia cannot be 1984 (gewurztraminer) or 1988 (pinot noir).**\n",
      "\n",
      "*   This deduction doesn't directly impact the probability matrices provided.\n",
      "\n",
      "**Deduction 10: Since the Bianca Flaux was bottled 4 years before the Vendemmia (clue 2), and the only remaining possibilities are 1992 and 1996, we can deduce that Bianca Flaux = 1992 and Vendemmia = 1996.**\n",
      "\n",
      "*   Bianca Flaux = 1992\n",
      "*   Vendemmia = 1996\n",
      "\n",
      "```\n",
      "(\"vintagesxwines\", 1.0, 2, 2) # 1992 is Bianca Flaux\n",
      "(\"vintagesxwines\", 0.0, 2, 0) # 1992 is not Annata Branco\n",
      "(\"vintagesxwines\", 0.0, 2, 1) # 1992 is not Ece Suss\n",
      "(\"vintagesxwines\", 0.0, 2, 3) # 1992 is not Vendemmia\n",
      "\n",
      "(\"vintagesxwines\", 1.0, 3, 3) # 1996 is Vendemmia\n",
      "(\"vintagesxwines\", 0.0, 3, 0) # 1996 is not Annata Branco\n",
      "(\"vintagesxwines\", 0.0, 3, 1) # 1996 is not Ece Suss\n",
      "(\"vintagesxwines\", 0.0, 3, 2) # 1996 is not Bianca Flaux\n",
      "```\n",
      "\n",
      "**Deduction 11: Since the Bianca Flaux is 1992, and the bottling order is Annata Branco -> Ece Suss -> Bianca Flaux, the Annata Branco must be 1984 and the Ece Suss must be 1988.**\n",
      "\n",
      "*   Annata Branco = 1984\n",
      "*   Ece Suss = 1988\n",
      "\n",
      "```\n",
      "(\"vintagesxwines\", 1.0, 0, 0) # 1984 is Annata Branco\n",
      "(\"vintagesxwines\", 0.0, 0, 1) # 1984 is not Ece Suss\n",
      "(\"vintagesxwines\", 0.0, 0, 2) # 1984 is not Bianca Flaux\n",
      "(\"vintagesxwines\", 0.0, 0, 3) # 1984 is not Vendemmia\n",
      "\n",
      "(\"vintagesxwines\", 1.0, 1, 1) # 1988 is Ece Suss\n",
      "(\"vintagesxwines\", 0.0, 1, 0) # 1988 is not Annata Branco\n",
      "(\"vintagesxwines\", 0.0, 1, 2) # 1988 is not Bianca Flaux\n",
      "(\"vintagesxwines\", 0.0, 1, 3) # 1988 is not Vendemmia\n",
      "```\n",
      "\n",
      "**Deduction 12: Now we can fill in the types. Annata Branco = 1984 = gewurztraminer, Ece Suss = 1988 = pinot noir, Bianca Flaux = 1992, and Vendemmia = 1996.**\n",
      "\n",
      "*   This deduction is already incorporated in previous deductions.\n",
      "\n",
      "**Deduction 13: Since the merlot is either the Annata Branco or the Bianca Flaux (clue 4), and the Annata Branco is the gewurztraminer, the Bianca Flaux must be the merlot.**\n",
      "\n",
      "*   Bianca Flaux = merlot\n",
      "\n",
      "```\n",
      "(\"winesxtypes\", 1.0, 2, 1) # Bianca Flaux is merlot\n",
      "(\"winesxtypes\", 0.0, 2, 0) # Bianca Flaux is not gewurztraminer\n",
      "(\"winesxtypes\", 0.0, 2, 2) # Bianca Flaux is not pinot noir\n",
      "(\"winesxtypes\", 0.0, 2, 3) # Bianca Flaux is not riesling\n",
      "```\n",
      "\n",
      "**Deduction 14: The only remaining type is riesling, so the Vendemmia must be the riesling.**\n",
      "\n",
      "*   Vendemmia = riesling\n",
      "\n",
      "```\n",
      "(\"winesxtypes\", 1.0, 3, 3) # Vendemmia is riesling\n",
      "(\"winesxtypes\", 0.0, 3, 0) # Vendemmia is not gewurztraminer\n",
      "(\"winesxtypes\", 0.0, 3, 1) # Vendemmia is not merlot\n",
      "(\"winesxtypes\", 0.0, 3, 2) # Vendemmia is not pinot noir\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "\n",
    "prob_agent_system_prompt = system_prompt\n",
    "\n",
    "prob_agent = agent = Agent(system_prompt=prob_agent_system_prompt)\n",
    "\n",
    "\n",
    "prob_agent_resp = prob_agent.perform_action(agent_job)\n",
    "\n",
    "print(prob_agent_resp)\n",
    "\n",
    "#data = json.loads(prob_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('update_matrix', <function update_matrix at 0x00000201383E8E50>)]\n",
      "['update_matrix:\\n\\n    Updates a probability matrix cell and normalizes related values.\\n    \\n    Parameters:\\n    matrices: dict - A key value pair consisting of matrix name as key and the corresponding numpy.ndarray probability matrix as value.\\n    matrix_name: Name of the matrix\\n    i, j: int - Indices of cell to update\\n    value: float - New probability value (0-1)\\n    \\n    Returns:\\n    matrix: numpy.ndarray - Updated probability matrix\\n    \\n    Example:\\n    >>> update_matrix({\"vinextypes\": np.full((3, 3), 1/3)}, \"vinextypes\", 0, 1, 0.6, 3)\\n    \\n\\n']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.utils import accumulate_tools\n",
    "\n",
    "\n",
    "tool_descriptions = accumulate_tools()\n",
    "print(tool_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"You are an expert in probability theory and are given a sequence a probability updates\n",
    "                        You are also given a tool to update these matrices and you need to call it sequentially\n",
    "                        The tools you have access to are:\n",
    "                        {\"\".join(tool_descriptions)}\n",
    "                        \\n\n",
    "                         \"\"\"\n",
    "\n",
    "agent_job = \"\"\"Analyze the updates and return the series of function calls required to make the changes active\n",
    "            Remember to return a valid JSON of only the function calls of the tool required to make the changes.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 0, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 2, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 2, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 3, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 0, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 1, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 1, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 3, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 2, \"value\": 0.0}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "prob_agent_2 = Agent(system_prompt + agent_job)\n",
    "\n",
    "\n",
    "new_query =f\"The categories are: {categories}\\n And here are the probability updates: {prob_agent_resp}\"\n",
    "\n",
    "prob_agent_2_resp = prob_agent_2.perform_action(new_query)\n",
    "\n",
    "print(prob_agent_2_resp)\n",
    "\n",
    "#data = json.loads(prob_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm_response(text):\n",
    "\n",
    "    json_start = text.find(\"json\")\n",
    "    json_data=None\n",
    "\n",
    "    if json_start != -1:\n",
    "        print(f\"JSON starts at index: {json_start}\")\n",
    "        json_string = text[json_start+4:-3]  # Extract potential JSON\n",
    "\n",
    "        print(json_string)\n",
    "        try:\n",
    "            json_data = json.loads(json_string)  # Validate JSON\n",
    "            print(\"Valid JSON found!\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON\")\n",
    "    else:\n",
    "        print(\"JSON not found\")\n",
    "\n",
    "    return json_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON starts at index: 3\n",
      "\n",
      "[\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 0, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 0, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 2, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxtypes\", \"i\": 1, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 2, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 2, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 3, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 3, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 0, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 0, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 1, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"vintagesxwines\", \"i\": 1, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 1, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 2, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 2, \"j\": 3, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 3, \"value\": 1.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 0, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 1, \"value\": 0.0},\n",
      "  {\"tool_name\": \"update_matrix\", \"matrix_name\": \"winesxtypes\", \"i\": 3, \"j\": 2, \"value\": 0.0}\n",
      "]\n",
      "\n",
      "Valid JSON found!\n"
     ]
    }
   ],
   "source": [
    "calls = load_llm_response(prob_agent_2_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_matrix(updated_matrices, matrix_name, row, col, prob_value):\n",
    "    \"\"\"\n",
    "    Update a specific cell in one of the probability matrices and then normalize \n",
    "    the matrix so each row and column sums to 1 (doubly stochastic).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrices : list of numpy.ndarray\n",
    "        List of probability matrices\n",
    "    matrix_index : int\n",
    "        Index of the matrix to update\n",
    "    row : int\n",
    "        Row index of the cell to update\n",
    "    col : int\n",
    "        Column index of the cell to update\n",
    "    prob_value : float\n",
    "        New probability value to set (must be between 0 and 1)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list of numpy.ndarray\n",
    "        Updated list of matrices with the specified matrix normalized\n",
    "    \"\"\"\n",
    "    # Validate probability value is between 0 and 1\n",
    "    if not 0 <= prob_value <= 1:\n",
    "        raise ValueError(\"Probability value must be between 0 and 1\")\n",
    "    \n",
    "    # Create a copy of the matrices to avoid modifying the original\n",
    "    \n",
    "    \n",
    "    # Update the specified cell\n",
    "    updated_matrices[matrix_name][row, col] = prob_value\n",
    "    \n",
    "    # Apply Sinkhorn-Knopp algorithm for double normalization\n",
    "    # (make both rows and columns sum to 1)\n",
    "    matrix = updated_matrices[matrix_name]\n",
    "    max_iterations = 100\n",
    "    tolerance = 1e-6\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        # Store matrix before iteration to check for convergence\n",
    "        prev_matrix = matrix.copy()\n",
    "        \n",
    "        # Normalize rows\n",
    "        row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "        matrix = matrix / row_sums\n",
    "        \n",
    "        # Normalize columns\n",
    "        col_sums = matrix.sum(axis=0, keepdims=True)\n",
    "        matrix = matrix / col_sums\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(matrix - prev_matrix)) < tolerance:\n",
    "            break\n",
    "    \n",
    "    updated_matrices[matrix_name] = matrix\n",
    "    return updated_matrices\n",
    "\n",
    "# Initialize three 4x4 matrices with equiprobable values\n",
    "def initialize_equiprobable_matrices(num_matrices=3, size=4):\n",
    "    \"\"\"\n",
    "    Create a list of matrices with equiprobable values,\n",
    "    where each row and column sums to 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_matrices : int\n",
    "        Number of matrices to create\n",
    "    size : int\n",
    "        Size of each matrix (size x size)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list of numpy.ndarray\n",
    "        List of initialized matrices\n",
    "    \"\"\"\n",
    "    matrices = []\n",
    "    \n",
    "    for _ in range(num_matrices):\n",
    "        # For a doubly stochastic matrix with equal values,\n",
    "        # each element must be 1/size\n",
    "        equi_prob = 1.0 / size\n",
    "        matrix = np.full((size, size), equi_prob)\n",
    "        matrices.append(matrix)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for call in calls:\n",
    "        fn_ = call[\"tool_name\"]\n",
    "        if fn_ == \"update_matrix\":\n",
    "            \n",
    "            updated_matrices = update_matrix(probability_matrices, matrix_name=call[\"matrix_name\"],\n",
    "                                                row=int(call[\"i\"]), col=int(call[\"j\"]),prob_value=float(call[\"value\"]))\n",
    "            \n",
    "            \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vintagesxtypes': array([[9.99632620e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.93505544e-01, 0.00000000e+00],\n",
      "       [1.83689907e-04, 5.00000000e-01, 3.24722809e-03, 5.00000000e-01],\n",
      "       [1.83689907e-04, 5.00000000e-01, 3.24722809e-03, 5.00000000e-01]]),\n",
      " 'vintagesxwines': array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]]),\n",
      " 'winesxtypes': array([[5.00000000e-01, 1.69093972e-04, 5.00000000e-01, 3.25024178e-03],\n",
      "       [5.00000000e-01, 1.69093972e-04, 5.00000000e-01, 3.25024178e-03],\n",
      "       [0.00000000e+00, 9.99661812e-01, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.93499516e-01]])}\n"
     ]
    }
   ],
   "source": [
    "pprint(updated_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nicholas and Edith are having a small dinner party this evening at their '\n",
      " \"home in Cedar Valley, and they've decided to open a select number of rare \"\n",
      " 'wines from their personal collection to celebrate the occasion. Using only '\n",
      " 'the clues below, match the vintages to the options from wines and types. '\n",
      " 'Remember, as with all grid-based logic puzzles, no option in any category '\n",
      " 'will ever be used more than once.\\n'\n",
      " '\\n'\n",
      " 'vintages : 1984, 1988, 1992, 1996.\\n'\n",
      " 'wines : Annata Branco, Bianca Flaux, Ece Suss, Vendemmia.\\n'\n",
      " 'types : gewurztraminer, merlot, pinot noir, riesling.\\n'\n",
      " '\\n'\n",
      " 'Clues:\\n'\n",
      " '1. The Ece Suss was bottled sometime after the Annata Branco.\\n'\n",
      " '2. The Bianca Flaux was bottled 4 years before the Vendemmia.\\n'\n",
      " '3. The 1988 bottle is a pinot noir.\\n'\n",
      " '4. The merlot is either the Annata Branco or the Bianca Flaux.\\n'\n",
      " '5. The Bianca Flaux was bottled sometime after the Ece Suss.\\n'\n",
      " '6. The 1984 bottle is a gewurztraminer.\\n'\n",
      " '\\n'\n",
      " 'While answering use the following format:\\n'\n",
      " 'Step-by-step solution:\\n'\n",
      " 'Your steps showing how you are solving the puzzle\\n'\n",
      " 'Final Answer:\\n'\n",
      " 'Fill the following table to show your final answer.\\n'\n",
      " '1984 | correct option from wines | correct option from types\\n'\n",
      " '1988 | correct option from wines | correct option from types\\n'\n",
      " '1992 | correct option from wines | correct option from types\\n'\n",
      " '1996 | correct option from wines | correct option from types\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(df[\"question\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"You are an expert in probability theory and you are given three matrices. Look at the matrices\n",
    "                    and finally deduce what category matches what. \n",
    "\n",
    "                    Final Answer:\\n'\n",
    "                    'Fill your answers as a table.\\n'\n",
    "                    Fill the following table to show your final answer.\\n'\n",
    "                    '1984 | correct option from wines | correct option from types\\n'\n",
    "                    '1988 | correct option from wines | correct option from types\\n'\n",
    "                    '1992 | correct option from wines | correct option from types\\n'\n",
    "                    '1996 | correct option from wines | correct option from types\\n') \n",
    "                                    \n",
    "                \"\"\"\n",
    "\n",
    "agent_job = f\"\"\"Analyze the probability matrix and look for the final solution\n",
    "\n",
    "                The matrices are: {updated_matrices}\n",
    "\n",
    "                The categories are: {categories}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided probability matrices, we can deduce the following relationships:\n",
      "\n",
      "*   **`vintagesxwines`**: This matrix directly maps vintages to wines. The identity matrix indicates a one-to-one correspondence.\n",
      "*   **`vintagesxtypes`**: This matrix maps vintages to types. The matrix indicates a strong correlation between 1984 and gewurztraminer, and 1988 and pinot noir. 1992 and 1996 are equally associated with merlot and riesling.\n",
      "*   **`winesxtypes`**: This matrix maps wines to types. Annata Branco and Bianca Flaux are equally associated with gewurztraminer and merlot. Ece Suss is strongly associated with pinot noir, and Vendemmia is strongly associated with riesling.\n",
      "\n",
      "Combining these relationships, we can infer the following:\n",
      "\n",
      "*   **1984** is strongly associated with **Annata Branco** and **gewurztraminer**.\n",
      "*   **1988** is strongly associated with **Ece Suss** and **pinot noir**.\n",
      "*   **1992** is strongly associated with **Bianca Flaux** and **merlot**.\n",
      "*   **1996** is strongly associated with **Vendemmia** and **riesling**.\n",
      "\n",
      "Here's the table summarizing the findings:\n",
      "\n",
      "| Vintage | Wine          | Type          |\n",
      "| :------ | :------------ | :------------ |\n",
      "| 1984    | Annata Branco | gewurztraminer |\n",
      "| 1988    | Ece Suss      | pinot noir    |\n",
      "| 1992    | Bianca Flaux  | merlot        |\n",
      "| 1996    | Vendemmia     | riesling      |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solution_agent_system_prompt = system_prompt\n",
    "\n",
    "solution_agent = Agent(system_prompt=solution_agent_system_prompt)\n",
    "\n",
    "\n",
    "solution_agent_resp = solution_agent.perform_action(agent_job)\n",
    "\n",
    "print(solution_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1984 | Annata Branco | gewurztraminer\\n'\n",
      " '1988 | Ece Suss | pinot noir\\n'\n",
      " '1992 | Bianca Flaux | merlot\\n'\n",
      " '1996 | Vendemmia | riesling')\n"
     ]
    }
   ],
   "source": [
    "pprint(df[\"answer\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../../GridPuzzle_gemini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Mistral-7b</th>\n",
       "      <th>Llama-13b</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>Claude-3</th>\n",
       "      <th>gemini-2.0-flash-exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341.json</td>\n",
       "      <td>802</td>\n",
       "      <td>Nicholas and Edith are having a small dinner p...</td>\n",
       "      <td>1984 | Annata Branco | gewurztraminer\\n1988 | ...</td>\n",
       "      <td>| 1984 | Annata Branco | gewurztraminer |\\n |-...</td>\n",
       "      <td>Let's solve the puzzle step by step.\\n \\n Step...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 6, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341.json</td>\n",
       "      <td>726</td>\n",
       "      <td>The world-famous Punta Santiago Rose Gardening...</td>\n",
       "      <td>first | bon silene | Renee\\nsecond | perle d'o...</td>\n",
       "      <td>| first | calocarpa | Hannah\\n |---------|----...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341.json</td>\n",
       "      <td>16</td>\n",
       "      <td>A standardized test has recently been develope...</td>\n",
       "      <td>55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...</td>\n",
       "      <td>| 55% | Zeno | CIT |\\n |------|------|-----|\\n...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 2, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, Pr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341.json</td>\n",
       "      <td>698</td>\n",
       "      <td>Gil Glabbers has lived on the coast of Guernse...</td>\n",
       "      <td>1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...</td>\n",
       "      <td>| 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 2, Tr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341.json</td>\n",
       "      <td>444</td>\n",
       "      <td>Jamie never misses an opportunity to watch the...</td>\n",
       "      <td>2 | April 22 | Eastbrook\\n9 | April 10 | Islet...</td>\n",
       "      <td>| Dates | Locations |\\n |---|---|\\n | April 10...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n Step 1: Analyze th...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key   id                                           question  \\\n",
       "0  341.json  802  Nicholas and Edith are having a small dinner p...   \n",
       "1  341.json  726  The world-famous Punta Santiago Rose Gardening...   \n",
       "2  341.json   16  A standardized test has recently been develope...   \n",
       "3  341.json  698  Gil Glabbers has lived on the coast of Guernse...   \n",
       "4  341.json  444  Jamie never misses an opportunity to watch the...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  1984 | Annata Branco | gewurztraminer\\n1988 | ...   \n",
       "1  first | bon silene | Renee\\nsecond | perle d'o...   \n",
       "2  55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...   \n",
       "3  1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...   \n",
       "4  2 | April 22 | Eastbrook\\n9 | April 10 | Islet...   \n",
       "\n",
       "                                          Mistral-7b  \\\n",
       "0  | 1984 | Annata Branco | gewurztraminer |\\n |-...   \n",
       "1  | first | calocarpa | Hannah\\n |---------|----...   \n",
       "2  | 55% | Zeno | CIT |\\n |------|------|-----|\\n...   \n",
       "3  | 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...   \n",
       "4  | Dates | Locations |\\n |---|---|\\n | April 10...   \n",
       "\n",
       "                                           Llama-13b  \\\n",
       "0  Let's solve the puzzle step by step.\\n \\n Step...   \n",
       "1  Let's break down the clues step by step:\\n \\n ...   \n",
       "2  Let's break down the clues and solve the puzzl...   \n",
       "3  Let's break down the clues step by step:\\n \\n ...   \n",
       "4  Let's break down the clues and solve the puzzl...   \n",
       "\n",
       "                                          gemini-pro  \\\n",
       "0  Step-by-step solution:\\n 1. From clue 6, we kn...   \n",
       "1  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "2  Step-by-step solution:\\n 1. From clue 2, we kn...   \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "\n",
       "                                         gpt-4-turbo  \\\n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...   \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, Pr...   \n",
       "3  Step-by-step solution:\\n \\n 1. From Clue 2, Tr...   \n",
       "4  Step-by-step solution:\\n \\n Step 1: Analyze th...   \n",
       "\n",
       "                                            Claude-3 gemini-2.0-flash-exp  \n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...                  NaN  \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 1, we...                  NaN  \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, we...                  NaN  \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...                  NaN  \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 3, we...                  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Mistral-7b</th>\n",
       "      <th>Llama-13b</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>Claude-3</th>\n",
       "      <th>gemini-2.0-flash-exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>341.json</td>\n",
       "      <td>13</td>\n",
       "      <td>A group of friends has decided to try several ...</td>\n",
       "      <td>3 | Raymond | vegan\\n5 | Wesley | gluten-free\\...</td>\n",
       "      <td>|------------|------------|\\n | 3 | Raymond |\\...</td>\n",
       "      <td>Let's solve the puzzle step by step!\\n \\n Step...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 3, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 3, we...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 3, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n1. From clue 3, Stuart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>341.json</td>\n",
       "      <td>821</td>\n",
       "      <td>Badgerville High's football team has selected ...</td>\n",
       "      <td>3 | Gordon Gregg | running back\\n4 | Kurt Koch...</td>\n",
       "      <td>|---------------------------------------------...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 4, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n Step 1: Analyze Cl...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Step-by-step solution:\\n\\n1.  From clue 3, Kur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>341.json</td>\n",
       "      <td>687</td>\n",
       "      <td>Using only the clues below, match the months t...</td>\n",
       "      <td>January | Rosie | shih tzu\\nFebruary | Lydia |...</td>\n",
       "      <td>| January | Kayla | schnauzer\\n | February | L...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n1. From clue 1, we kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>341.json</td>\n",
       "      <td>718</td>\n",
       "      <td>A number of new space probes were launched thi...</td>\n",
       "      <td>January | Viria Mari | Mercury\\nFebruary | Iun...</td>\n",
       "      <td>Step-by-step solution:\\n From clue 1, we know ...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 2, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Step-by-step solution:\\n1. From clue 2, Disty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>341.json</td>\n",
       "      <td>350</td>\n",
       "      <td>The Albion Amateur Astronomy Club proudly proc...</td>\n",
       "      <td>2008 | Jack Ingram | Peinope\\n2009 | Hal Grego...</td>\n",
       "      <td>| 2008 | Jack Ingram | Crecci or Ken Jones |\\n...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n1. From clue 1, the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key   id                                           question  \\\n",
       "6   341.json   13  A group of friends has decided to try several ...   \n",
       "9   341.json  821  Badgerville High's football team has selected ...   \n",
       "10  341.json  687  Using only the clues below, match the months t...   \n",
       "12  341.json  718  A number of new space probes were launched thi...   \n",
       "19  341.json  350  The Albion Amateur Astronomy Club proudly proc...   \n",
       "\n",
       "                                               answer  \\\n",
       "6   3 | Raymond | vegan\\n5 | Wesley | gluten-free\\...   \n",
       "9   3 | Gordon Gregg | running back\\n4 | Kurt Koch...   \n",
       "10  January | Rosie | shih tzu\\nFebruary | Lydia |...   \n",
       "12  January | Viria Mari | Mercury\\nFebruary | Iun...   \n",
       "19  2008 | Jack Ingram | Peinope\\n2009 | Hal Grego...   \n",
       "\n",
       "                                           Mistral-7b  \\\n",
       "6   |------------|------------|\\n | 3 | Raymond |\\...   \n",
       "9   |---------------------------------------------...   \n",
       "10  | January | Kayla | schnauzer\\n | February | L...   \n",
       "12  Step-by-step solution:\\n From clue 1, we know ...   \n",
       "19  | 2008 | Jack Ingram | Crecci or Ken Jones |\\n...   \n",
       "\n",
       "                                            Llama-13b  \\\n",
       "6   Let's solve the puzzle step by step!\\n \\n Step...   \n",
       "9   Let's break down the clues and solve the puzzl...   \n",
       "10  Let's break down the clues step by step:\\n \\n ...   \n",
       "12  Let's break down the clues and solve the puzzl...   \n",
       "19  Let's break down the clues step by step:\\n \\n ...   \n",
       "\n",
       "                                           gemini-pro  \\\n",
       "6   Step-by-step solution:\\n 1. From clue 3, we kn...   \n",
       "9   Step-by-step solution:\\n 1. From clue 4, we kn...   \n",
       "10  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "12  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "19  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "\n",
       "                                          gpt-4-turbo  \\\n",
       "6   Step-by-step solution:\\n \\n 1. From Clue 3, we...   \n",
       "9   Step-by-step solution:\\n \\n Step 1: Analyze Cl...   \n",
       "10  Step-by-step solution:\\n \\n 1. From Clue 1, we...   \n",
       "12  Step-by-step solution:\\n \\n 1. From Clue 2, we...   \n",
       "19  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "\n",
       "                                             Claude-3  \\\n",
       "6   Step-by-step solution:\\n 1. From clue 3, we kn...   \n",
       "9   Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "10  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "12  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "19  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "\n",
       "                                 gemini-2.0-flash-exp  \n",
       "6   Step-by-step solution:\\n1. From clue 3, Stuart...  \n",
       "9   Step-by-step solution:\\n\\n1.  From clue 3, Kur...  \n",
       "10  Step-by-step solution:\\n1. From clue 1, we kno...  \n",
       "12  Step-by-step solution:\\n1. From clue 2, Disty ...  \n",
       "19  Step-by-step solution:\\n1. From clue 1, the co...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-by-step solution:\n",
      "1. From clue 3, Stuart lost 7 lbs.\n",
      "2. From clue 5, Wesley lost 5 lbs.\n",
      "3. From clue 1, Stuart lost 4 more pounds than the person who used the vegan diet. Since Stuart lost 7 lbs, the vegan diet resulted in a 3 lb loss.\n",
      "4. From clue 2, the gluten-free dieter lost 2 more pounds than Raymond. This means Raymond did not lose 7 lbs (Stuart lost 7 lbs) and Raymond did not lose 5 lbs (Wesley lost 5 lbs) and Raymond did not lose 3 lbs (Vegan diet resulted in 3 lbs). So, Raymond lost 9 lbs, which makes the gluten-free diet result in 9+2 = 11 lbs, which is impossible, so Raymond must have lost less than 7, and the gluten free dieter did as well. So this leaves 3 lbs lost, and 5 lbs lost for Raymond. Because the vegan dieter lost 3 lbs, Raymond lost 5 lbs, which means the gluten-free dieter lost 7 lbs.\n",
      "5. From clue 4, the dieter who lost 7 lbs (Stuart) is either the person who used the caveman diet or Raymond. Since the gluten-free dieter lost 7 lbs, the dieter who lost 7 lbs could not have been Raymond, so Stuart used the gluten-free diet.\n",
      "6. Since Stuart used the gluten-free diet, Raymond did not, and Wesley did not use the vegan diet, and Stuart did not use the vegan diet, and Raymond did not use the gluten-free diet, and Wesley did not use the gluten-free diet, Tom must have used the vegan diet. Raymond lost 5 lbs and Wesley lost 5 lbs, but each person lost a different amount, so this cannot be true. Let's re-evaluate\n",
      "1. Stuart lost 7 lbs\n",
      "2. Wesley lost 5 lbs\n",
      "3. Vegan diet resulted in 3 lb loss\n",
      "4. Gluten-free dieter lost 2 more lbs than Raymond, so Raymond can't have 7lbs. Also, since Raymond isn't vegan, gluten-free, or 7 lbs, Raymond either lost 9 or 5 lbs. The gluten-free dieter lost 2 more, which would be 11 and 7 respectively. 11 isn't valid, so we need to have Raymond lost 5 and the gluten-free lost 7\n",
      "5. Stuart lost 7 lbs, and the 7 lb dieter is either caveman or Raymond. Since the gluten-free dieter lost 7 lbs, Stuart is the gluten-free. Since Wesley lost 5 lbs, and Raymond lost 5 lbs, this cannot be true.\n",
      "\n",
      "Ok, let's try this\n",
      "1. Stuart lost 7\n",
      "2. Wesley lost 5\n",
      "3. Vegan lost 3\n",
      "4. Gluten-free = Raymond + 2\n",
      "5. Stuart (7) = caveman or Raymond\n",
      "\n",
      "From 4, since Raymond + 2, Raymond can't have 7 (Stuart), 3(vegan) or 5(wesley). So Raymond must have lost 9 lbs, and gluten-free lost 11, which is impossible. We need a number lower than 7, so that Raymond + 2 results in something under 10. Vegan = 3, Wesley = 5, Stuart = 7. So Raymond + 2 = someone under 10.\n",
      "This means the Raymond can only have 3 or 5 pounds lost\n",
      "Stuart lost 4 more pounds than the vegan (3lbs), thus Stuart lost 7.\n",
      "\n",
      "Stuart is either Raymond or caveman. Raymond cannot be 7, Raymond cannot be 3, Raymond cannot be 5. Raymond is 9! Gluten free (Raymond + 2 = 11, impossible).\n",
      "\n",
      "There's an error in the instructions, as 3 people lost different amounts, only to have Raymond and Wesley lose the same amount. The clues above conflict with the original premise. Since Wesley lost 5lbs, and Raymond lost 5lbs, they lost the same amount.\n",
      "\n",
      "Final Answer:\n",
      "3 | Tom | vegan\n",
      "5 | Wesley | caveman\n",
      "7 | Stuart | gluten-free\n",
      "9 | Raymond | dairy-free\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_non[\"gemini-2.0-flash-exp\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 | Raymond | vegan\n",
      "5 | Wesley | gluten-free\n",
      "7 | Stuart | caveman\n",
      "9 | Tom | dairy-free\n"
     ]
    }
   ],
   "source": [
    "print(df_non[\"answer\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 821, 687, 718, 350, 1084, 1677, 1437, 1597, 1935, 1020, 1495, 2893, 2208, 2700, 2788, 3720, 3936, 3642, 3659, 4465, 4658, 4087, 4861, 4140, 4464, 4848, 3954, 5740, 5675, 5212, 4976, 5889, 5659, 5325, 5585, 6843, 6292, 6045, 6432, 6823, 5923, 6778, 6997, 7685, 7865, 7183, 7389, 7866, 7188, 7837, 8712, 7959, 8356, 8142, 7993, 8519, 9106, 9719, 9139, 9487, 8853, 8988, 9043, 9497, 9596, 9965, 10037, 10380, 10100, 10450, 10440, 9976, 10251, 11592, 11097, 11022, 11603, 11546, 11748, 11263, 11367, 11407, 11304, 11321, 11923, 12703, 12356, 12535, 12172, 12133, 12395, 12818, 13003, 12900, 13407, 13198, 12782, 13051, 12980]\n"
     ]
    }
   ],
   "source": [
    "print(df_non[\"id\"].values.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
