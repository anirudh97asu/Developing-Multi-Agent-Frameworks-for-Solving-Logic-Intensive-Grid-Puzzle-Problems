{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.llm_engine.gemini_agent import Agent\n",
    "\n",
    "#agent = ChatAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Mistral-7b</th>\n",
       "      <th>Llama-13b</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>Claude-3</th>\n",
       "      <th>actual_question</th>\n",
       "      <th>Clues</th>\n",
       "      <th>categories</th>\n",
       "      <th>number_of_clues</th>\n",
       "      <th>number_categories</th>\n",
       "      <th>category_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341.json</td>\n",
       "      <td>802</td>\n",
       "      <td>Nicholas and Edith are having a small dinner p...</td>\n",
       "      <td>1984 | Annata Branco | gewurztraminer\\n1988 | ...</td>\n",
       "      <td>| 1984 | Annata Branco | gewurztraminer |\\n |-...</td>\n",
       "      <td>Let's solve the puzzle step by step.\\n \\n Step...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 6, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 6, we...</td>\n",
       "      <td>Nicholas and Edith are having a small dinner p...</td>\n",
       "      <td>Clues:\\n1. The Ece Suss was bottled sometime a...</td>\n",
       "      <td>vintages : 1984, 1988, 1992, 1996.\\nwines : An...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>vintages wines types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341.json</td>\n",
       "      <td>726</td>\n",
       "      <td>The world-famous Punta Santiago Rose Gardening...</td>\n",
       "      <td>first | bon silene | Renee\\nsecond | perle d'o...</td>\n",
       "      <td>| first | calocarpa | Hannah\\n |---------|----...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 1, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>The world-famous Punta Santiago Rose Gardening...</td>\n",
       "      <td>Clues:\\n1. The rose that won fourth place was ...</td>\n",
       "      <td>placements : first, second, third, fourth.\\nro...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>placements roses gardeners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341.json</td>\n",
       "      <td>16</td>\n",
       "      <td>A standardized test has recently been develope...</td>\n",
       "      <td>55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...</td>\n",
       "      <td>| 55% | Zeno | CIT |\\n |------|------|-----|\\n...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n 1. From clue 2, we kn...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, Pr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 4, we...</td>\n",
       "      <td>A standardized test has recently been develope...</td>\n",
       "      <td>Clues:\\n1. Zeno finished with a score that was...</td>\n",
       "      <td>scores : 55%, 62%, 69%, 76%.\\na.i. : Archimede...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>scores institutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341.json</td>\n",
       "      <td>698</td>\n",
       "      <td>Gil Glabbers has lived on the coast of Guernse...</td>\n",
       "      <td>1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...</td>\n",
       "      <td>| 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...</td>\n",
       "      <td>Let's break down the clues step by step:\\n \\n ...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From Clue 2, Tr...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 2, we...</td>\n",
       "      <td>Gil Glabbers has lived on the coast of Guernse...</td>\n",
       "      <td>Clues:\\n1. The message from Plymouth was sent ...</td>\n",
       "      <td>year sent : 1962, 1969, 1976, 1983.\\nwriters :...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>sent writers origins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341.json</td>\n",
       "      <td>444</td>\n",
       "      <td>Jamie never misses an opportunity to watch the...</td>\n",
       "      <td>2 | April 22 | Eastbrook\\n9 | April 10 | Islet...</td>\n",
       "      <td>| Dates | Locations |\\n |---|---|\\n | April 10...</td>\n",
       "      <td>Let's break down the clues and solve the puzzl...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 1, we...</td>\n",
       "      <td>Step-by-step solution:\\n \\n Step 1: Analyze th...</td>\n",
       "      <td>Step-by-step solution:\\n \\n 1. From clue 3, we...</td>\n",
       "      <td>Jamie never misses an opportunity to watch the...</td>\n",
       "      <td>Clues:\\n1. The outing to Eastbrook logged 7 fe...</td>\n",
       "      <td>shooting stars : 2, 9, 16, 23.\\ndates : April ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>stars dates locations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key   id                                           question  \\\n",
       "0  341.json  802  Nicholas and Edith are having a small dinner p...   \n",
       "1  341.json  726  The world-famous Punta Santiago Rose Gardening...   \n",
       "2  341.json   16  A standardized test has recently been develope...   \n",
       "3  341.json  698  Gil Glabbers has lived on the coast of Guernse...   \n",
       "4  341.json  444  Jamie never misses an opportunity to watch the...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  1984 | Annata Branco | gewurztraminer\\n1988 | ...   \n",
       "1  first | bon silene | Renee\\nsecond | perle d'o...   \n",
       "2  55% | Archimedes | CIT\\n62% | Galen | UCLA\\n69...   \n",
       "3  1962 | Tracy | Cherbourg\\n1969 | Felipe | Bour...   \n",
       "4  2 | April 22 | Eastbrook\\n9 | April 10 | Islet...   \n",
       "\n",
       "                                          Mistral-7b  \\\n",
       "0  | 1984 | Annata Branco | gewurztraminer |\\n |-...   \n",
       "1  | first | calocarpa | Hannah\\n |---------|----...   \n",
       "2  | 55% | Zeno | CIT |\\n |------|------|-----|\\n...   \n",
       "3  | 1962 | Felipe (Bournemouth) |\\n | 1969 | Kar...   \n",
       "4  | Dates | Locations |\\n |---|---|\\n | April 10...   \n",
       "\n",
       "                                           Llama-13b  \\\n",
       "0  Let's solve the puzzle step by step.\\n \\n Step...   \n",
       "1  Let's break down the clues step by step:\\n \\n ...   \n",
       "2  Let's break down the clues and solve the puzzl...   \n",
       "3  Let's break down the clues step by step:\\n \\n ...   \n",
       "4  Let's break down the clues and solve the puzzl...   \n",
       "\n",
       "                                          gemini-pro  \\\n",
       "0  Step-by-step solution:\\n 1. From clue 6, we kn...   \n",
       "1  Step-by-step solution:\\n 1. From clue 1, we kn...   \n",
       "2  Step-by-step solution:\\n 1. From clue 2, we kn...   \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "\n",
       "                                         gpt-4-turbo  \\\n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...   \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, Pr...   \n",
       "3  Step-by-step solution:\\n \\n 1. From Clue 2, Tr...   \n",
       "4  Step-by-step solution:\\n \\n Step 1: Analyze th...   \n",
       "\n",
       "                                            Claude-3  \\\n",
       "0  Step-by-step solution:\\n \\n 1. From clue 6, we...   \n",
       "1  Step-by-step solution:\\n \\n 1. From clue 1, we...   \n",
       "2  Step-by-step solution:\\n \\n 1. From clue 4, we...   \n",
       "3  Step-by-step solution:\\n \\n 1. From clue 2, we...   \n",
       "4  Step-by-step solution:\\n \\n 1. From clue 3, we...   \n",
       "\n",
       "                                     actual_question  \\\n",
       "0  Nicholas and Edith are having a small dinner p...   \n",
       "1  The world-famous Punta Santiago Rose Gardening...   \n",
       "2  A standardized test has recently been develope...   \n",
       "3  Gil Glabbers has lived on the coast of Guernse...   \n",
       "4  Jamie never misses an opportunity to watch the...   \n",
       "\n",
       "                                               Clues  \\\n",
       "0  Clues:\\n1. The Ece Suss was bottled sometime a...   \n",
       "1  Clues:\\n1. The rose that won fourth place was ...   \n",
       "2  Clues:\\n1. Zeno finished with a score that was...   \n",
       "3  Clues:\\n1. The message from Plymouth was sent ...   \n",
       "4  Clues:\\n1. The outing to Eastbrook logged 7 fe...   \n",
       "\n",
       "                                          categories  number_of_clues  \\\n",
       "0  vintages : 1984, 1988, 1992, 1996.\\nwines : An...                6   \n",
       "1  placements : first, second, third, fourth.\\nro...                5   \n",
       "2  scores : 55%, 62%, 69%, 76%.\\na.i. : Archimede...                5   \n",
       "3  year sent : 1962, 1969, 1976, 1983.\\nwriters :...                5   \n",
       "4  shooting stars : 2, 9, 16, 23.\\ndates : April ...                4   \n",
       "\n",
       "   number_categories              category_names  \n",
       "0                  3        vintages wines types  \n",
       "1                  3  placements roses gardeners  \n",
       "2                  2         scores institutions  \n",
       "3                  3        sent writers origins  \n",
       "4                  3       stars dates locations  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"../data/GridPuzzle_processed.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Clues:\\n'\n",
      " '1. The outing to Eastbrook logged 7 fewer shooting stars than the trip to '\n",
      " 'Isleton.\\n'\n",
      " '2. The April 17 outing was in Gilmore City.\\n'\n",
      " '3. The outing where they saw 16 shooting stars was in Gilmore City.\\n'\n",
      " '4. The April 10 outing logged 7 more shooting stars than the April 22 '\n",
      " 'outing.\\n'\n",
      " 'shooting stars : 2, 9, 16, 23.\\n'\n",
      " 'dates : April 7, April 10, April 17, April 22.\\n'\n",
      " 'locations : Eastbrook, Gilmore City, Isleton, Manchester.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(df[\"Clues\"].iloc[4] + \"\\n\"+ df[\"categories\"].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"llm_agent\"\n",
    "system_prompt = \"\"\"You are a logic grid puzzle solving assistant that produces clear deductive steps. When solving puzzles:\\n\\n1. Skip repeating the original clues - assume they're already understood.\\n\\n2. Start immediately with meaningful deductions derived from combining and analyzing clues.\\n\\n3. For each numbered deduction step:\\n   - Present only the NEW inference or conclusion reached\\n   - Briefly explain which constraints led to this conclusion\\n   - Show any concrete mappings or assignments that result (X = Y, A cannot be B, etc.)\\n\\n4. Include specific variable assignments and eliminations in your steps (e.g., \\\"Wine A must be from 1988\\\" or \\\"Person B cannot have the red car\\\").\\n\\n5. Focus on recording the mapping progression - which variables have been definitively assigned and which possibilities have been eliminated.\\n\\n6. Document crucial decision points and branching logic when necessary.\\n\\n7. Each step must contribute new information toward the solution without repeating previous deductions.\\n\\n8. When appropriate, summarize the current state of the solution grid after significant deductions.\\n\\nYour output should read like the step-by-step solution path in a puzzle solver's notebook, and do not return any solution directly\"\"\"\n",
    "\n",
    "agent = Agent(agent_name=agent_name, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clues = df[\"Clues\"].iloc[0]\n",
    "categories = df[\"categories\"].iloc[0]\n",
    "\n",
    "user_query = clues + \"\\n\" + categories\n",
    "\n",
    "llm_agent_response = agent.perform_action(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  From clues 1 and 5, the bottling order is Annata Branco -> Ece Suss -> Bianca Flaux.\n",
      "\n",
      "2.  Clue 2: Bianca Flaux was bottled 4 years before Vendemmia.\n",
      "\n",
      "3.  Clue 6: 1984 = gewurztraminer.\n",
      "\n",
      "4.  Clue 3: 1988 = pinot noir.\n",
      "\n",
      "5.  Combining clue 2 and the vintages, Bianca Flaux and Vendemmia must be either 1984/1988 or 1992/1996. Since 1984 and 1988 are taken:\n",
      "    *   Bianca Flaux = 1992\n",
      "    *   Vendemmia = 1996\n",
      "\n",
      "6.  From step 1 and 5, the order is Annata Branco -> Ece Suss -> Bianca Flaux (1992). Therefore:\n",
      "    *   Ece Suss cannot be 1996.\n",
      "    *   Annata Branco cannot be 1992 or 1996.\n",
      "\n",
      "7.  Since Bianca Flaux = 1992 and Vendemmia = 1996, and the order is Annata Branco -> Ece Suss -> Bianca Flaux, then:\n",
      "    *   Annata Branco = 1984\n",
      "    *   Ece Suss = 1988\n",
      "\n",
      "8.  Combining steps 3 and 7:\n",
      "    *   Annata Branco (1984) = gewurztraminer\n",
      "\n",
      "9.  Combining steps 4 and 7:\n",
      "    *   Ece Suss (1988) = pinot noir\n",
      "\n",
      "10. Clue 4: merlot is either Annata Branco or Bianca Flaux. Since Annata Branco is gewurztraminer (step 8):\n",
      "    *   Bianca Flaux = merlot\n",
      "\n",
      "11. Combining steps 5 and 10:\n",
      "    *   Bianca Flaux (1992) = merlot\n",
      "\n",
      "12. The only remaining wine type is riesling, and the only remaining wine is Vendemmia. Therefore:\n",
      "    *   Vendemmia = riesling\n",
      "\n",
      "13. Combining steps 5 and 12:\n",
      "    *   Vendemmia (1996) = riesling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(llm_agent_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January | Rosie | shih tzu\n",
      "February | Lydia | black lab\n",
      "March | Kayla | schnauzer\n",
      "April | Violet | boxer\n"
     ]
    }
   ],
   "source": [
    "print(df[\"answer\"].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def initialize_probability_tables(num_categories, categories, cat_topics):\n",
    "    \"\"\"\n",
    "    Initialize uniform probability matrices for all pairs of categories.\n",
    "    \n",
    "    Parameters:\n",
    "    num_categories: int - Number of categories\n",
    "    categories: list - List of category strings with comma-separated subcategories\n",
    "    \n",
    "    Returns:\n",
    "    matrices: dict - Maps category index tuples to probability matrices\n",
    "    category_mapping: dict - Maps topic strings to category index tuples\n",
    "    \n",
    "    Example:\n",
    "    >>> matrices, mapping = initialize_probability_tables(3, [\"red, blue\", \"small, large\", \"cheap, expensive\"])\n",
    "    \"\"\"\n",
    "    r = 2\n",
    "    combinations_ls = list(combinations(np.arange(num_categories), r))\n",
    "    matrices = {}\n",
    "    for index, combination in enumerate(combinations_ls):\n",
    "        c1 , c2 = categories[combination[0]].split(\", \"), categories[combination[1]].split(\", \")\n",
    "       \n",
    "        matrix =  np.full((len(c1), len(c2)), 1 / max(len(c1), len(c2)))\n",
    "        topic = cat_topics[combination[0]] + \"x\" + cat_topics[combination[1]]\n",
    "        matrices[topic] = matrix\n",
    "       \n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['vintages', 'wines', 'types']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "cat_topics = []\n",
    "categories = []\n",
    "cat_str = df[\"categories\"].iloc[0].split(\"\\n\")\n",
    "for item in cat_str:\n",
    "    cat_topics.append(item.split(\" : \")[0])\n",
    "    categories.append(item.split(\" : \")[1])\n",
    "\n",
    "print(type(cat_topics), cat_topics)\n",
    "\n",
    "probability_matrices = initialize_probability_tables(len(categories), categories, cat_topics) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def populate_categories(categories, index):\n",
    "    \n",
    "    cat_topics = []\n",
    "    categories = []\n",
    "\n",
    "    cat_str = df[\"categories\"].iloc[index].split(\"\\n\")\n",
    "    for item in cat_str:\n",
    "        cat_topics.append(item.split(\" : \")[0])\n",
    "        categories.append(item.split(\" : \")[1].split(\", \"))\n",
    "\n",
    "    examples = {}\n",
    "    r = 2\n",
    "    combinations_ls = list(combinations(np.arange(len(cat_topics)), r))\n",
    "\n",
    "    for topic_cob in combinations_ls:\n",
    "        values = []\n",
    "        key_1, key_2 = topic_cob\n",
    "        for i in range(len(categories[0])):\n",
    "            for j in range(len(categories[0])):\n",
    "\n",
    "                values.append((categories[key_1][i], categories[key_2][j]))\n",
    "\n",
    "        examples[cat_topics[topic_cob[0]] + \"__x__\" + cat_topics[topic_cob[1]]] = values\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=4\n",
    "examples = populate_categories(categories=categories, index=index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are a logical reasoning agent.\n",
    "\n",
    "                    Given a complex sequential list of logical statements about n-categories and corresponding n-2D matrices depicting inter-category\n",
    "                    item mappings, systematically deconstruct each logical deduction. Critically evaluate the relational insights, translating these\n",
    "                    abstract logical statements into quantitative probability weights for specific matrix cells. \n",
    "                    The weighting process should be nuanced, reflecting the contextual strength, coherence, and inferential power of each logical\n",
    "                    statement as it relates to the underlying categorical relationships.\n",
    "                    \n",
    "                    Comprehending Deductions & Updating Probabilities\n",
    "                        \n",
    "                        Carefully process each logical deduction, ensuring clarity by merging sequential steps when appropriate.\n",
    "                        Use conclusive deductions to:\n",
    "\n",
    "                            Identify the relevant probability matrix that requires updating.\n",
    "                            Determine the exact cells to modify, assigning new weights based on the strength of the deduction.\n",
    "\n",
    "                    Dynamic Adjustments\n",
    "\n",
    "                        Continuously reassess all decisions as new information becomes available.\n",
    "                        If new deductions conflict with prior reasoning, promptly revise the probability matrix or discard incorrect conclusions.\n",
    "                        Ensure that all updates reflect the most accurate and up-to-date analysis.\n",
    "\n",
    "                    Use these probability values if the information you find fall into one of the categories:\n",
    "                        \n",
    "                        - Definite: 1.0\n",
    "                        - Eliminated: 0.0\n",
    "                        - Uncertain: 0.5\n",
    "                        - Most Likely: 0.6-0.9\n",
    "                    \n",
    "                    Remember, as with all grid-based logic puzzles, no option in any category will ever be used more than once.\n",
    "                    Your task is to maintain precision and adaptability, ensuring logical consistency in every update.\n",
    "                \"\"\"\n",
    "\n",
    "agent_job = f\"\"\"Process the given  resources below and give the output as expected in the format below.\n",
    "                \n",
    "                Available Resources:\n",
    "                        'Logical Step-By-Step Deductions': {llm_agent_response},\n",
    "                        'Initial Probability Matrices': {probability_matrices},\n",
    "                        'Category Mapping': {df[\"categories\"].iloc[3]}\n",
    "\n",
    "                - You should use the format below\n",
    "\n",
    "                    *** (\"matrix_name\", probability_value, row_index, column_index)\n",
    "\n",
    "                Return the sequence of probability updates\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Logical Reasoning Mapping Framework\n",
    "\n",
    "                    Input: \n",
    "                    - Set of logical deductions and it's associated reasoning\n",
    "                    - Item-item pairs\n",
    "                    - Category Pair Names\n",
    "\n",
    "                    Objective:\n",
    "                    Assign probabilistic weights to item-item mappings based on:\n",
    "                    1. Reasoning clarity\n",
    "                    2. Evidential strength\n",
    "                    3. Logical coherence\n",
    "                    4. Contextual relevance\n",
    "\n",
    "                    Mapping Probability Scale:\n",
    "                    - 1.0: Absolute Certainty (Unequivocal logical proof)\n",
    "                    - 0.75-0.9: Moderate Confidence (Solid but Indirect Reasoning)\n",
    "                    - 0.4-0.5: Low Confidence (Weak or Circumstantial Reasoning)\n",
    "                    - 0.1-0.35: Minimal Confidence (Speculative Reasoning)\n",
    "                    - 0.0: No Confidence (No Viable Logical Connection)\n",
    "\n",
    "                    Evaluation Criteria:\n",
    "                    - Direct Logical Chain: Maximize probability\n",
    "                    - Indirect Inference: Moderate probability\n",
    "                    - Circumstantial Evidence: Reduce probability\n",
    "                    - Contradictory Evidence: Zero probability\n",
    "                    \n",
    "                    Ultimate Goal:\n",
    "                        - Compare each deduction and item-item pair and based on its relevance and reasoning assign probability weights.\n",
    "                        - Remember, as with all grid-based logic puzzles, no item in any pair will ever be used more than once. \n",
    "                                                       \n",
    "                \"\"\"\n",
    "\n",
    "agent_job = f\"\"\"Process the given  resources below and give the output as expected in the format below.\n",
    "                \n",
    "                Available Resources:\n",
    "                        'Logical Step-By-Step Deductions': {llm_agent_response},\n",
    "                        'Item-Item Mapping': {examples},\n",
    "                        'Topic Pairs': {list(examples.keys())}\n",
    "\n",
    "                Remember, as with all grid-based logic puzzles, no item in any pair will ever be used more than once. \n",
    "                Return the assigned weights for item-item mapping\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"ingredients\": [\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 0,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 1,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 2,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 3,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 4,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 5,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 6,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 7,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 8,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 9,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 10,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 11,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 12,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 13,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 14,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxwines\",\n",
      "        \"Pair_Index\": 15,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 0,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 1,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 2,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 3,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 4,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 5,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 6,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 7,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 8,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 9,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 10,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 11,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 12,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 13,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 14,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"vintagesxtypes\",\n",
      "        \"Pair_Index\": 15,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 0,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 1,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 2,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 3,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 4,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 5,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 6,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 7,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 8,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 9,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 10,\n",
      "        \"Probability\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 11,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 12,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 13,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 14,\n",
      "        \"Probability\": 0.0\n",
      "      },\n",
      "      {\n",
      "        \"Topic_Pair\": \"winesxtypes\",\n",
      "        \"Pair_Index\": 15,\n",
      "        \"Probability\": 1.0\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "prob_agent = agent = Agent(agent_name=\"prob_agent_1\", system_prompt=system_prompt, json=True)\n",
    "\n",
    "\n",
    "prob_agent_resp = prob_agent.perform_action(agent_job)\n",
    "\n",
    "print(prob_agent_resp)\n",
    "\n",
    "data = json.loads(prob_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0][\"ingredients\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ingredient in data[0][\"ingredients\"]:\n",
    "    if  ingredient.get(\"Probability\") is not None and ingredient[\"Probability\"] > 0.0:\n",
    "        print(examples[ingredient[\"Topic_Pair\"]][ingredient[\"Pair_Index\"]], ingredient[\"Topic_Pair\"], ingredient[\"Probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2 | April 22 | Eastbrook\\n'\n",
      " '9 | April 10 | Isleton\\n'\n",
      " '16 | April 17 | Gilmore City\\n'\n",
      " '23 | April 7 | Manchester')\n"
     ]
    }
   ],
   "source": [
    "pprint(df[\"answer\"].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'year sent : 1962, 1969, 1976, 1983.\\nwriters : Felipe, Karla, Sean, Tracy.\\norigins : Bournemouth, Cherbourg, Le Havre, Plymouth.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"categories\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('update_matrix', <function update_matrix at 0x000001BE06698F70>)]\n",
      "['update_matrix:\\n\\n    Update a specific cell in one of the probability matrices and then normalize \\n    the matrix so each row and column sums to 1 (doubly stochastic).\\n    \\n    Parameters:\\n    -----------\\n    matrices : list of numpy.ndarray\\n        List of probability matrices\\n    matrix_index : int\\n        Index of the matrix to update\\n    row : int\\n        Row index of the cell to update\\n    col : int\\n        Column index of the cell to update\\n    prob_value : float\\n        New probability value to set (must be between 0 and 1)\\n        \\n    Returns:\\n    --------\\n    list of numpy.ndarray\\n        Updated list of matrices with the specified matrix normalized\\n    \\n\\n']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.utils import accumulate_tools\n",
    "\n",
    "\n",
    "tool_descriptions = accumulate_tools()\n",
    "print(tool_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"You are an expert in probability theory and are given a sequence a probability updates\n",
    "                        You are also given a tool to update these matrices and you need to call it sequentially\n",
    "                        The tools you have access to are:\n",
    "                        {\"\".join(tool_descriptions)}\n",
    "                        \\n\n",
    "                         \"\"\"\n",
    "\n",
    "agent_job = \"\"\"Analyze the updates and return the series of function calls required to make the changes active\n",
    "            Remember to return a valid JSON of only the function calls of the tool required to make the changes.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxwines\",\n",
      "    \"i\": 0,\n",
      "    \"j\": 3,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxwines\",\n",
      "    \"i\": 1,\n",
      "    \"j\": 2,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxwines\",\n",
      "    \"i\": 2,\n",
      "    \"j\": 1,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxwines\",\n",
      "    \"i\": 3,\n",
      "    \"j\": 0,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxtypes\",\n",
      "    \"i\": 0,\n",
      "    \"j\": 3,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxtypes\",\n",
      "    \"i\": 1,\n",
      "    \"j\": 1,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxtypes\",\n",
      "    \"i\": 2,\n",
      "    \"j\": 2,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"vintagesxtypes\",\n",
      "    \"i\": 3,\n",
      "    \"j\": 0,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"winesxtypes\",\n",
      "    \"i\": 0,\n",
      "    \"j\": 3,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"winesxtypes\",\n",
      "    \"i\": 1,\n",
      "    \"j\": 1,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"winesxtypes\",\n",
      "    \"i\": 2,\n",
      "    \"j\": 2,\n",
      "    \"value\": 1.0\n",
      "  },\n",
      "  {\n",
      "    \"tool_name\": \"update_matrix\",\n",
      "    \"matrix_name\": \"winesxtypes\",\n",
      "    \"i\": 3,\n",
      "    \"j\": 0,\n",
      "    \"value\": 1.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "prob_agent_2 = Agent(agent_name=\"prob_agent_2\", system_prompt=system_prompt + agent_job, json=True)\n",
    "\n",
    "\n",
    "new_query =f\"The categories are: {categories}\\n And here are the probability updates: {prob_agent_resp}\"\n",
    "\n",
    "prob_agent_2_resp = prob_agent_2.perform_action(new_query)\n",
    "\n",
    "print(prob_agent_2_resp)\n",
    "\n",
    "#data = json.loads(prob_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "calls = json.loads(prob_agent_2_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vintagesxwines': array([[0.17839458, 0.17839458, 0.17839458, 0.46481623],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459]]), 'vintagesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.192708  , 0.192708  , 0.12613596, 0.48844831],\n",
      "       [0.19905803, 0.19905803, 0.47574784, 0.12613586],\n",
      "       [0.30411699, 0.30411699, 0.1990581 , 0.19270792],\n",
      "       [0.30411699, 0.30411699, 0.1990581 , 0.19270792]]), 'vintagesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.21087991, 0.1388529 , 0.13360744, 0.51666   ],\n",
      "       [0.21813276, 0.1436285 , 0.50463142, 0.1336074 ],\n",
      "       [0.22669655, 0.49082194, 0.14362841, 0.13885277],\n",
      "       [0.34429078, 0.22669666, 0.21813273, 0.21087982]]), 'vintagesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.17839458, 0.17839458, 0.17839458, 0.46481623],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.192708  , 0.12613596, 0.192708  , 0.48844831],\n",
      "       [0.19905803, 0.47574784, 0.19905803, 0.12613586],\n",
      "       [0.30411699, 0.1990581 , 0.30411699, 0.19270792],\n",
      "       [0.30411699, 0.1990581 , 0.30411699, 0.19270792]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.21087991, 0.13360744, 0.1388529 , 0.51666   ],\n",
      "       [0.21813276, 0.50463142, 0.1436285 , 0.1336074 ],\n",
      "       [0.22669655, 0.14362841, 0.49082194, 0.13885277],\n",
      "       [0.34429078, 0.21813273, 0.22669666, 0.21087982]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]), 'winesxtypes': array([[0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25],\n",
      "       [0.25, 0.25, 0.25, 0.25]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]), 'winesxtypes': array([[0.17839458, 0.17839458, 0.17839458, 0.46481623],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459],\n",
      "       [0.27386847, 0.27386847, 0.27386847, 0.17839459]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]), 'winesxtypes': array([[0.192708  , 0.12613596, 0.192708  , 0.48844831],\n",
      "       [0.19905803, 0.47574784, 0.19905803, 0.12613586],\n",
      "       [0.30411699, 0.1990581 , 0.30411699, 0.19270792],\n",
      "       [0.30411699, 0.1990581 , 0.30411699, 0.19270792]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]), 'winesxtypes': array([[0.21087991, 0.13360744, 0.1388529 , 0.51666   ],\n",
      "       [0.21813276, 0.50463142, 0.1436285 , 0.1336074 ],\n",
      "       [0.22669655, 0.14362841, 0.49082194, 0.13885277],\n",
      "       [0.34429078, 0.21813273, 0.22669666, 0.21087982]])}\n",
      "\n",
      "\n",
      "{'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]), 'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]), 'winesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]])}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_matrix(updated_matrices, matrix_name, row, col, prob_value):\n",
    "    \"\"\"\n",
    "    Update a specific cell in one of the probability matrices and then normalize \n",
    "    the matrix so each row and column sums to 1 (doubly stochastic).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrices : list of numpy.ndarray\n",
    "        List of probability matrices\n",
    "    matrix_index : int\n",
    "        Index of the matrix to update\n",
    "    row : int\n",
    "        Row index of the cell to update\n",
    "    col : int\n",
    "        Column index of the cell to update\n",
    "    prob_value : float\n",
    "        New probability value to set (must be between 0 and 1)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list of numpy.ndarray\n",
    "        Updated list of matrices with the specified matrix normalized\n",
    "    \"\"\"\n",
    "    # Validate probability value is between 0 and 1\n",
    "    if not 0 <= prob_value <= 1:\n",
    "        raise ValueError(\"Probability value must be between 0 and 1\")\n",
    "    \n",
    "    # Create a copy of the matrices to avoid modifying the original\n",
    "    \n",
    "    \n",
    "    # Update the specified cell\n",
    "    updated_matrices[matrix_name][row, col] = prob_value\n",
    "    \n",
    "    #Apply Sinkhorn-Knopp algorithm for double normalization\n",
    "   # (make both rows and columns sum to 1)\n",
    "    matrix = updated_matrices[matrix_name]\n",
    "    max_iterations = 100\n",
    "    tolerance = 1e-6\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        # Store matrix before iteration to check for convergence\n",
    "        prev_matrix = matrix.copy()\n",
    "        \n",
    "        # Normalize rows\n",
    "        row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "        matrix = matrix / row_sums\n",
    "        \n",
    "        # Normalize columns\n",
    "        col_sums = matrix.sum(axis=0, keepdims=True)\n",
    "        matrix = matrix / col_sums\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(matrix - prev_matrix)) < tolerance:\n",
    "            break\n",
    "    \n",
    "    updated_matrices[matrix_name] = matrix\n",
    "    return updated_matrices\n",
    "\n",
    "\n",
    "for call in calls:\n",
    "    fn_ = call[\"tool_name\"]\n",
    "    if fn_ == \"update_matrix\":\n",
    "        \n",
    "\n",
    "        #print(probability_matrices[\"placementsxroses\"])\n",
    "\n",
    "        updated_matrices = update_matrix(probability_matrices, matrix_name=call[\"matrix_name\"],\n",
    "                                            row=int(call[\"i\"]), col=int(call[\"j\"]),prob_value=float(call[\"value\"])\n",
    "                                            )        \n",
    "        print(updated_matrices)\n",
    "        print()\n",
    "        print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.15 + 0.15 + 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vintagesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]]),\n",
      " 'vintagesxwines': array([[0.15618339, 0.14889484, 0.14297412, 0.55194797],\n",
      "       [0.1618281 , 0.15427613, 0.54092178, 0.14297405],\n",
      "       [0.16852956, 0.52829953, 0.1542761 , 0.14889475],\n",
      "       [0.51345894, 0.16852949, 0.161828  , 0.15618323]]),\n",
      " 'winesxtypes': array([[0.15618339, 0.14297412, 0.14889484, 0.55194797],\n",
      "       [0.1618281 , 0.54092178, 0.15427613, 0.14297405],\n",
      "       [0.16852956, 0.1542761 , 0.52829953, 0.14889475],\n",
      "       [0.51345894, 0.161828  , 0.16852949, 0.15618323]])}\n"
     ]
    }
   ],
   "source": [
    "pprint(updated_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"You are an expert in probability theory and you are given three matrices. Look at the matrices\n",
    "                    and finally deduce what category matches what. \n",
    "\n",
    "                    Final Answer:\\n'\n",
    "                    'Fill your answers as a table.\\n'\n",
    "                    Fill the following table to show your final answer.\\n'\n",
    "                    'first | correct option from roses | correct option from gardeners\\n'\n",
    "                    'second | correct option from roses | correct option from gardeners\\n'\n",
    "                    'third | correct option from roses | correct option from gardeners\\n'\n",
    "                    'fourth | correct option from roses | correct option from gardeners\\n') \n",
    "                    Remember, as with all grid-based logic puzzles, no option in any category will ever be used more than once.\n",
    "\n",
    "                                    \n",
    "                \"\"\"\n",
    "\n",
    "agent_job = f\"\"\"Analyze the probability matrix and look for the final solution\n",
    "                The matrices are: {updated_matrices}\n",
    "                The categories are: {categories}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1962, 1969, 1976, 1983.',\n",
       " 'Felipe, Karla, Sean, Tracy.',\n",
       " 'Bournemouth, Cherbourg, Le Havre, Plymouth.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year sentxwriters': array([[0.19713932, 0.19297986, 0.        , 0.60987978],\n",
      "       [0.36974032, 0.06978979, 0.50533101, 0.05513967],\n",
      "       [0.36333057, 0.35566462, 0.        , 0.28100428],\n",
      "       [0.06978979, 0.38156573, 0.49466899, 0.05397627]]), 'year sentxorigins': array([[0.18365323, 0.40817354, 0.        , 0.40817354],\n",
      "       [0.        , 0.21851621, 0.56296707, 0.21851621],\n",
      "       [0.42663331, 0.18083309, 0.21170063, 0.18083309],\n",
      "       [0.38971346, 0.19247716, 0.2253323 , 0.19247716]]), 'writersxorigins': array([[0.29454426, 0.        , 0.16938876, 0.53606669],\n",
      "       [0.52098327, 0.24906788, 0.11439783, 0.11555089],\n",
      "       [0.18447247, 0.23097529, 0.47739524, 0.10715713],\n",
      "       [0.        , 0.51995683, 0.23881817, 0.24122529]])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set print options to suppress scientific notation and show 8 decimal places\n",
    "np.set_printoptions(suppress=True, precision=8)\n",
    "\n",
    "# Now when you print your arrays, they'll show exact decimal values\n",
    "print(updated_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I will analyze the probability matrices to deduce the relationships between the categories: years, writers, and origins. The goal is to find the most probable associations between each element of the categories based on the provided matrices.\n",
      "\n",
      "Here's the strategy:\n",
      "\n",
      "1.  **Examine the Matrices:** Understand what each matrix represents.\n",
      "    *   `year sentxwriters`: Probability of a year being associated with a writer.\n",
      "    *   `year sentxorigins`: Probability of a year being associated with an origin.\n",
      "    *   `writersxorigins`: Probability of a writer being associated with an origin.\n",
      "\n",
      "2.  **Find Strongest Probabilities:** Look for the highest probability values in each row of the matrices. These indicate the strongest associations.\n",
      "\n",
      "3.  **Deduce Relationships:** Combine the information from all three matrices to form a consistent mapping between years, writers, and origins.\n",
      "\n",
      "4.  **Ensure Uniqueness:** Make sure that each element from each category is used only once.\n",
      "\n",
      "Let's apply this strategy:\n",
      "\n",
      "*Categories:*\n",
      "\n",
      "*   Years: 1962, 1969, 1976, 1983\n",
      "*   Writers: Felipe, Karla, Sean, Tracy\n",
      "*   Origins: Bournemouth, Cherbourg, Le Havre, Plymouth\n",
      "\n",
      "*Matrix Analysis:*\n",
      "\n",
      "1.  **`year sentxwriters`:**\n",
      "    *   1962: Highest probability with Tracy (0.60987978)\n",
      "    *   1969: Highest probability with Felipe (0.36974032)\n",
      "    *   1976: Highest probability with Felipe (0.36333057)\n",
      "    *   1983: Highest probability with Karla (0.38156573)\n",
      "\n",
      "2.  **`year sentxorigins`:**\n",
      "    *   1962: Highest probability with Cherbourg/Plymouth (0.40817354)\n",
      "    *   1969: Highest probability with Le Havre (0.56296707)\n",
      "    *   1976: Highest probability with Bournemouth (0.42663331)\n",
      "    *   1983: Highest probability with Bournemouth (0.38971346)\n",
      "\n",
      "3.  **`writersxorigins`:**\n",
      "    *   Felipe: Highest probability with Bournemouth (0.52098327)\n",
      "    *   Karla: Highest probability with Cherbourg (0.51995683)\n",
      "    *   Sean: Highest probability with Le Havre (0.47739524)\n",
      "    *   Tracy: Highest probability with Plymouth (0.53606669)\n",
      "\n",
      "*Deductions and Mapping:*\n",
      "\n",
      "1.  From `writersxorigins`, we have:\n",
      "    *   Felipe - Bournemouth\n",
      "    *   Karla - Cherbourg\n",
      "    *   Sean - Le Havre\n",
      "    *   Tracy - Plymouth\n",
      "\n",
      "2.  From `year sentxwriters`, we have:\n",
      "    *   1962 - Tracy\n",
      "    *   1969 - Felipe\n",
      "    *   1983 - Karla\n",
      "\n",
      "3.  From `year sentxorigins`, we have:\n",
      "    *   1962 - Plymouth\n",
      "    *   1969 - Le Havre\n",
      "    *   1983 - Bournemouth\n",
      "\n",
      "4.  Combining these:\n",
      "    *   1962 - Tracy - Plymouth\n",
      "    *   1969 - Felipe - Le Havre\n",
      "    *   1983 - Karla - Bournemouth\n",
      "\n",
      "5.  The only remaining year is 1976 and the only remaining writer is Sean and the only remaining origin is Cherbourg.\n",
      "    *   1976 - Sean - Cherbourg\n",
      "\n",
      "*Final Answer Table:*\n",
      "\n",
      "```\n",
      "first | correct option from roses | correct option from gardeners\n",
      "---|---|---\n",
      "1962 | Tracy | Plymouth\n",
      "1969 | Felipe | Le Havre\n",
      "1976 | Sean | Cherbourg\n",
      "1983 | Karla | Bournemouth\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "solution_agent_system_prompt = system_prompt\n",
    "\n",
    "solution_agent = Agent(agent_name=\"solution_agent\", system_prompt=solution_agent_system_prompt)\n",
    "\n",
    "\n",
    "solution_agent_resp = solution_agent.perform_action(agent_job)\n",
    "\n",
    "print(solution_agent_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1962 | Tracy | Cherbourg\\n'\n",
      " '1969 | Felipe | Bournemouth\\n'\n",
      " '1976 | Karla | Plymouth\\n'\n",
      " '1983 | Sean | Le Havre')\n"
     ]
    }
   ],
   "source": [
    "pprint(df[\"answer\"].iloc[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
