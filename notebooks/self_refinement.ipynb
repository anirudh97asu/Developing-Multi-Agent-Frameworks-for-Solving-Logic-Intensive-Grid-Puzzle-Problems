{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from groq import Groq\n",
    "from src.llm_engine.gemini_agent import Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./data/GridPuzzle_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d76404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Groq(\n",
    "#     api_key= os.getenv(\"GROQ_API_KEY\"),\n",
    "# )\n",
    "\n",
    "client = Groq(api_key= os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1ea77",
   "metadata": {},
   "source": [
    "#### GROQ: Self-Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf74c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./deepseek_refinement_responses\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc45a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[821,\n",
       " 897,\n",
       " 919,\n",
       " 13,\n",
       " 16,\n",
       " 244,\n",
       " 350,\n",
       " 411,\n",
       " 444,\n",
       " 503,\n",
       " 656,\n",
       " 687,\n",
       " 688,\n",
       " 698,\n",
       " 718,\n",
       " 726,\n",
       " 743,\n",
       " 744,\n",
       " 755,\n",
       " 802]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_ =[]\n",
    "for file in os.listdir(path):\n",
    "    id_ = file.split(\"_\")[-1].split(\".\")[0]\n",
    "    ids_.append(int(id_))\n",
    "\n",
    "ids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c96ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, APIStatusError\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    id_ = row[\"id\"]\n",
    "    if id_ not in ids_:\n",
    "        user_query = row[\"question\"]\n",
    "\n",
    "        try:\n",
    "\n",
    "            groq_deepseek_response = \"\"\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"deepseek-r1-distill-llama-70b\",\n",
    "                messages=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_query\n",
    "\n",
    "                    }],\n",
    "                temperature=0,\n",
    "                max_completion_tokens=8192,\n",
    "                top_p=1,\n",
    "                stream=True,\n",
    "                stop=None,\n",
    "            )\n",
    "\n",
    "            for chunk in completion:\n",
    "                text = chunk.choices[0].delta.content or \"\"\n",
    "                groq_deepseek_response += text\n",
    "\n",
    "            self_refinement = \"\"\"Now that you've proposed a solution, critically review your work. Verify that you've properly interpreted all clues\n",
    "            and reached a valid conclusion. If you identify any errors or inconsistencies in your reasoning, please reconsider the puzzle and provide\n",
    "            a corrected solution.\"\"\"\n",
    "\n",
    "            new_query = self_refinement + \"\\n\" + \"Your Response: \\n\" + groq_deepseek_response\n",
    "            return_seq = row[\"question\"].split(\"Final Answer:\")[1]\n",
    "            new_query += return_seq + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "            new_completion = client.chat.completions.create(\n",
    "                model=\"deepseek-r1-distill-llama-70b\",\n",
    "                messages=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": new_query\n",
    "\n",
    "                    }],\n",
    "                temperature=0,\n",
    "                max_completion_tokens=8192,\n",
    "                top_p=1,\n",
    "                stream=True,\n",
    "                stop=None,\n",
    "            )\n",
    "\n",
    "            final_response = \"\"\n",
    "            for new_chunk in new_completion:\n",
    "                text = new_chunk.choices[0].delta.content or \"\"\n",
    "                final_response += text\n",
    "\n",
    "\n",
    "            with open(os.path.join(path, f\"deepseek_refinement_{id_}.txt\"), \"w\") as f:\n",
    "                f.write(final_response)\n",
    "        \n",
    "        except Exception as e:\n",
    "            with open(os.path.join(path, f\"deepseek_api_status_error_refinement_{id_}.txt\"), \"w\") as f:\n",
    "                f.write(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9570178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nicholas and Edith are having a small dinner party this evening at their home in Cedar Valley, and they've decided to open a select number of rare wines from their personal collection to celebrate the occasion. Using only the clues below, match the vintages to the options from wines and types. Remember, as with all grid-based logic puzzles, no option in any category will ever be used more than once.\n",
      "\n",
      "vintages : 1984, 1988, 1992, 1996.\n",
      "wines : Annata Branco, Bianca Flaux, Ece Suss, Vendemmia.\n",
      "types : gewurztraminer, merlot, pinot noir, riesling.\n",
      "\n",
      "Clues:\n",
      "1. The Ece Suss was bottled sometime after the Annata Branco.\n",
      "2. The Bianca Flaux was bottled 4 years before the Vendemmia.\n",
      "3. The 1988 bottle is a pinot noir.\n",
      "4. The merlot is either the Annata Branco or the Bianca Flaux.\n",
      "5. The Bianca Flaux was bottled sometime after the Ece Suss.\n",
      "6. The 1984 bottle is a gewurztraminer.\n",
      "\n",
      "While answering use the following format:\n",
      "Step-by-step solution:\n",
      "Your steps showing how you are solving the puzzle\n",
      "Final Answer:\n",
      "Fill the following table to show your final answer.\n",
      "1984 | correct option from wines | correct option from types\n",
      "1988 | correct option from wines | correct option from types\n",
      "1992 | correct option from wines | correct option from types\n",
      "1996 | correct option from wines | correct option from types\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[\"question\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf45f8",
   "metadata": {},
   "source": [
    "#### GEMINI Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./gemini_refinement_responses\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b62aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(system_prompt=\"You are an AI assistant\", agent_name=\"csp_agent\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    id_ = row[\"id\"]\n",
    "    \n",
    "    user_query = row[\"question\"]\n",
    "\n",
    "    response = agent.perform_action(user_query=user_query)\n",
    "\n",
    "    try:\n",
    "        self_refinement = \"\"\"Now that you've proposed a solution, critically review your work. Verify that you've properly interpreted all clues\n",
    "        and reached a valid conclusion. If you identify any errors or inconsistencies in your reasoning, please reconsider the puzzle and provide\n",
    "        a corrected solution.\"\"\"\n",
    "\n",
    "        new_query = self_refinement + \"\\n\" + \"Your Response: \\n\" + response\n",
    "        return_seq = row[\"question\"].split(\"Final Answer:\")[1]\n",
    "        new_query += return_seq + \"\\n\"\n",
    "\n",
    "        final_response = agent.perform_action(user_query=new_query)\n",
    "\n",
    "\n",
    "        with open(os.path.join(path, f\"gemini_refinement_pred_{id_}.txt\"), \"w\") as f:\n",
    "            f.write(final_response)\n",
    "    \n",
    "    except Exception as e:\n",
    "        with open(os.path.join(path, f\"gemini_refinement_api_error_pred_{id_}.txt\"), \"w\") as f:\n",
    "            f.write(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
